# Пересдача по предмету "Фундаментальные концепции ИИ"

---

## Объем задач:
- [X] ЛР №1
- [X] ЛР №2
- [X] ЛР №3
- [X] ЛР №4
- [X] ЛР №5
- [X] Курсач `*.ipynb`

---

# Задание по Курсовой работе: 

### Описание курсовой работы

#### Цель курсовой работы

1. **Описание датасета**:
   - Краткое описание: что представляет собой датасет, откуда он взят, для каких задач может быть использован.
   - Пример данных: визуализация (например, изображение или таблица с примером данных).
   - Даталоадер: создание класса или функции, которая предоставляет API для работы с данными. Этот инструмент должен:
     - Обеспечивать доступ к данным "на лету".
     - Реализовывать методы для разбиения данных (например, на обучающую и тестовую выборки).
     - Позволять выводить пример данных без необходимости полной загрузки датасета (например, данные могут храниться в облаке).

2. **Статистический анализ данных**:
   - Основная статистика:
     - Количество полей (фичей) и их типы.
     - Количество классов (если данные классифицированы).
     - Объем данных (количество строк, размер в мегабайтах и т.д.).
     - Процентное соотношение классов (если применимо).
     - Количество пропущенных значений.
   - Дополнительная статистика (если требуется):
     - Распределение данных по фичам.
     - Корреляция между фичами.
     - Анализ выбросов (outliers).

3. **Алгоритмы машинного обучения**:
   - Выбор задачи: на одном и том же датасете можно решать разные задачи (классификация, регрессия, кластеризация и т.д.). Необходимо выбрать конкретную задачу.
   - Пример алгоритма: привести пример алгоритма машинного обучения, который может быть применен к данному датасету. Описать, как алгоритм работает и какие задачи решает.
   - Инференс: 
     - Сохранить веса обученной модели.
     - Продемонстрировать работу модели на новых данных (например, в ноутбуке или презентации).
     - Показать, что модель действительно работает и может быть использована на практике.

4. **Кластеризация и понижение размерности**:
   - Кластеризация: применить методы кластеризации (например, KMeans, DBSCAN) к данным и проанализировать результаты.
   - Понижение размерности: использовать методы, такие как PCA или t-SNE, чтобы визуализировать данные в меньшей размерности и показать, как данные группируются.

5. **Анализ выбросов (outliers)**:
   - Выявить выбросы в данных (если они есть).
   - Показать, как эти выбросы влияют на результаты анализа или обучения модели.
   - Если датасет небольшой, можно вручную проанализировать выбросы.

6. **Проектирование ML-систем (ML-systems design)**:
   - Привести примеры, где данный датасет и выбранные алгоритмы могут быть использованы в реальных продакшн-системах.
   - Описать преимущества и недостатки датасета в контексте таких систем.
   - Пример: Waymo Open Dataset — хороший пример датасета, который используется в автономных транспортных системах.

---

# Задание по лабороторной работе

## Лабораторная работа №1 - Градиентный спуск и его модификации.

- [X] Выбрать 2x тестовые функции оптимизации
- [X] Запрограммировать собственную реализацию классического градиентного спуска
- [X] Запрограммировать пайлайн тестирования алгоритма оптимизации
  - [X] Визуализации функции и точки оптимума
  - [X] Вычисление погрешности найденного решения в сравнение с аналитическим для нескольких запусков
  - [X] Визуализации точки найденного решения
- [X] Запрограммировать метод вычисления градиента
  - [X] Передача функции градиента от пользователя
  - [X] Символьное вычисление градиента например с помощью `sympy`
  - [ ] Численная аппроксимация градиента
- [X] Запрограммировать одну моментную модификацию и протестировать ее
- [X] Запрограммировать одну адаптивную модификацию и протестировать ее
- [X] Запрограммировать метод эфолюции темпа обучения и/или метод выбора начального приближения и протестировать их

## Лабораторная работа №2 - Global optimization and metaheuristic algortihms.

- [X] В Pygmo запрогроммировать две своих тестовых функции и найти их оптимум 3 разными алгоритмами доступными в библиотеке и получить таблицу сравнения

## Лабораторная работа №3 - Оптимизация гиперпараметров.

### GUIDE по поднятию БД:

Запустить контейнер

```bash
docker-compose up optuna
```

Положить контейнер

```bash
docker-compose down
```

---

- [X] С помощью optuna взять пример, аналогичный третьему туториалу документации, используя sklearn и с другим датасетом, выбрать другие алгоритмы классификации и клстеризации не из туториала и визуализировать графики для полученного процесса.
  - [X] В качестве других моделей подойдут любые алгоритмы классификации и регрессии из sklearn которые не использовались в туториале.
- [X] Использовать 2 разных семплера и прунера.
- [X] При процессе оптимизации гиперпараметров использовать общую память через postgreSQL.
- [X] В качестве отчёта выступают: исходный код, инструкция запуска реляционной БД.

## Лабораторная работа №4 - Восстановление функции распределения вероятности.

- [X] Реализовать метод восстановления плотности вероятности двумя способами:
    - [X] EM-алгоритм
    - [X] Ядерное сглаживание
- [X] Применить данные методы на любом наборе случайных точек

## Лабораторная работа №5 - Реализовать метод Метрополиса-Гастингса и Гибсона для несимметричного распределения.

Применить два метода на основе той функции плотности, которая была восстановлена в прошлом пункте, тем самым получив изначальные точки.

- [ ] В методе М-Г нарисовать картинку блуждания в случае 3D-функции плотности (на доп баллы)
- [ ] Сравнить красный и синий набор точек (сгенерированые и исходные) (с помощью Расстояния Кульбака-Лейблера)