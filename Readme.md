# Фундаментальные концепции Искусственного интеллекта (ФКИИ)

Репозиторий содержит учебные материалы, лабораторные работы и курсовые проекты по предмету "Фундаментальные концепции ИИ". Проект разделен на два семестра, каждый с собственным набором заданий и проектов.

## Структура проекта

```
/Users/cube/Desktop/FKII/
├── 1 семестр/
│   ├── Readme.md
│   ├── Курсач/
│   ├── Лабораторная работа №1/
│   ├── Лабораторная работа №2/
│   ├── Лабораторная работа №3/
│   ├── Лабораторная работа №4/
│   └── Лабораторная работа №5/
├── 2 семестр/
│   ├── Readme.md
│   ├── homework/
│   └── Курсач/
└── Readme.md
```

## 1 семестр

Первый семестр посвящен изучению методов оптимизации, метаэвристических алгоритмов и статистических методов.

### Лабораторные работы

1. **Лабораторная работа №1 - Градиентный спуск и его модификации**
   - Реализация классического градиентного спуска
   - Разработка пайплайна тестирования алгоритма оптимизации
   - Реализация методов вычисления градиента
   - Реализация моментных и адаптивных модификаций
   - Методы эволюции темпа обучения

2. **Лабораторная работа №2 - Глобальная оптимизация и метаэвристические алгоритмы**
   - Использование библиотеки Pygmo
   - Реализация тестовых функций оптимизации
   - Сравнение различных алгоритмов (PSO, GA, CMA-ES)
   - Анализ эффективности алгоритмов на разных функциях

3. **Лабораторная работа №3 - Оптимизация гиперпараметров**
   - Работа с базами данных для хранения результатов
   - Использование Docker для развертывания окружения

4. **Лабораторная работа №4 - Восстановление функции распределения вероятности**
   - Реализация EM-алгоритма
   - Реализация ядерного сглаживания
   - Применение методов на наборах случайных точек

5. **Лабораторная работа №5 - Методы Монте-Карло**
   - Реализация метода Метрополиса-Гастингса
   - Реализация метода Гибсона для несимметричного распределения
   - Сравнение сгенерированных и исходных наборов точек
   - Оценка с помощью расстояния Кульбака-Лейблера

### Курсовая работа 1 семестра

Курсовая работа включает:
- Описание и анализ датасета
- Статистический анализ данных
- Применение алгоритмов машинного обучения
- Кластеризацию и понижение размерности
- Анализ выбросов

## 2 семестр

Второй семестр фокусируется на практическом применении алгоритмов машинного обучения.

### Домашние задания

В папке `homework` находятся:
- `hw_trees_rf_final.ipynb` - Jupyter notebook с домашним заданием по теме "Деревья решений и случайный лес". Задание включает:
  - Теоретические основы построения решающих деревьев
  - Реализацию алгоритмов для нахождения оптимальных разбиений с использованием информационных критериев
  - Работу с категориальными признаками
  - Реализацию бэггинга и случайного леса
  - Оценку качества моделей по различным метрикам (accuracy, precision, recall, AUC-ROC)
  - Анализ важности признаков

- Наборы данных для работы:
  - `diabetes.csv` - датасет для предсказания диабета
  - `students.csv` - преобразованный датасет User Knowledge для классификации

### Курсовая работа 2 семестра

В папке `Курсач` находится:
- `Курсовая_работа_по_МЛ.ipynb` - Jupyter notebook с курсовой работой по машинному обучению, использующей:
  - CatBoost - библиотеку градиентного бустинга от Яндекса
  - Optuna - библиотеку для автоматизированного подбора гиперпараметров
  - SHAP - библиотеку для интерпретации моделей машинного обучения

## Технологии и инструменты

- Python и библиотеки для анализа данных (NumPy, Pandas, Matplotlib)
- Библиотеки машинного обучения (scikit-learn, CatBoost)
- Инструменты оптимизации (Pygmo, Optuna)
- Инструменты для интерпретации моделей (SHAP)
- Docker для контейнеризации

## Как использовать

Каждая лабораторная работа и курсовой проект содержат Jupyter notebooks с подробными комментариями и пояснениями. Для запуска необходимо установить соответствующие зависимости, указанные в начале каждого notebook.

        